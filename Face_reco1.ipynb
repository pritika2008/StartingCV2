{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_-OVIu2W_Lz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "import face_recognition\n",
        "\n",
        "# Define the folder where images are stored\n",
        "FOLDER_NAME = 'images'\n",
        "images, names = [], []\n",
        "finger_tips = [8, 12, 16, 20] # Other than the thumb tip ('4')\n",
        "thumb_tip = 4\n",
        "\n",
        "# Load images and names from the folder\n",
        "myList = os.listdir(FOLDER_NAME) # This will take all the items in that folder and store them into a list\n",
        "print(\"Images Found:\", myList)\n",
        "for numImg in myList:\n",
        "    curImg = cv2.imread(f'{FOLDER_NAME}/{numImg}') # Read each image\n",
        "    images.append(curImg) # Add images to the list\n",
        "    names.append(os.path.splitext(numImg)[0]) # Store names without file extensions\n",
        "\n",
        "# Initialize Mediapipe hands model\n",
        "mp_holistic = mp.solutions.holistic\n",
        "mpHands = mp.solutions.hands\n",
        "hands = mpHands.Hands()\n",
        "mpDraw = mp.solutions.drawing_utils\n",
        "\n",
        "# User preferences for optional features\n",
        "runit = input(\"Do you want to include hand landmarks? (yes/no): \") == \"yes\"\n",
        "runit2 = input(\"Do you want contours? (yes/no): \") == \"yes\"\n",
        "runit3 = input(\"Do you want sounds? (yes/no): \") == \"yes\"\n",
        "\n",
        "# Function to encode face images\n",
        "def encoding(imagesc):\n",
        "    encodeList = []\n",
        "    for img in imagesc:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        encode = face_recognition.face_encodings(img)[0] # Get face encodings\n",
        "        encodeList.append(encode)\n",
        "    return encodeList\n",
        "\n",
        "knownEncodeList = encoding(images) # Generate known encodings\n",
        "print('Face encoding completed')\n",
        "\n",
        "# Function to detect hand landmarks\n",
        "def hand_landmark_finder(img, h, w, c):\n",
        "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    results = hands.process(imgRGB) # Process the hand landmarks\n",
        "    if results.multi_hand_landmarks:\n",
        "        for handLms in results.multi_hand_landmarks:\n",
        "            lm_list = [lm for lm in handLms.landmark]\n",
        "            finger_fold_status = []\n",
        "            for tip in finger_tips:\n",
        "                x, y = int(lm_list[tip].x * w), int(lm_list[tip].y * h)\n",
        "                cv2.circle(img, (x, y), 15, (0, 255, 0), cv2.FILLED) # Draw circles on fingertips\n",
        "                if lm_list[tip].x < lm_list[tip - 3].x:\n",
        "                    cv2.circle(img, (x, y), 15, (255, 0, 0), cv2.FILLED)\n",
        "                    finger_fold_status.append(True)\n",
        "                else:\n",
        "                    finger_fold_status.append(False)\n",
        "            if lm_list[thumb_tip].y < lm_list[thumb_tip - 1].y < lm_list[thumb_tip - 2].y:\n",
        "                print(\"Like\")\n",
        "                cv2.putText(img, \"Like\", (30, 20), cv2.FONT_ITALIC, 1, (0, 255, 0), 3)\n",
        "                if runit3:\n",
        "                    os.system(\"say 'yay'\")\n",
        "            elif lm_list[thumb_tip].y > lm_list[thumb_tip - 1].y > lm_list[thumb_tip - 2].y:\n",
        "                print(\"Dislike\")\n",
        "                cv2.putText(img, \"Dislike\", (30, 20), cv2.FONT_ITALIC, 1, (255, 0, 0), 3)\n",
        "                if runit3:\n",
        "                    os.system(\"say 'aww man'\")\n",
        "            mpDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS) # Draw hand connections\n",
        "\n",
        "# Start video capture\n",
        "cap = cv2.VideoCapture(0) # Start recording\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    h, w, c = img.shape\n",
        "    imgShape = cv2.resize(img, (0, 0), None, 0.25, 0.25) # Resize the video for faster processing\n",
        "    imgShape = cv2.cvtColor(imgShape, cv2.COLOR_BGR2RGB)\n",
        "    frameFace = face_recognition.face_locations(imgShape) # Find face locations\n",
        "    encodeFrame = face_recognition.face_encodings(imgShape, frameFace) # Get face encodings\n",
        "\n",
        "    # Draw contours if enabled\n",
        "    if runit2:\n",
        "        imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        ret, thresh = cv2.threshold(imgray, 100, 255, 0) # Apply thresholding\n",
        "        contours, hierarchy = cv2.findContours(thresh, 1, 2)\n",
        "        cv2.drawContours(img, contours, -1, (0, 0, 0), 3) # Draw contours\n",
        "\n",
        "    # Recognize faces\n",
        "    for ef, fl in zip(encodeFrame, frameFace):\n",
        "        matches = face_recognition.compare_faces(knownEncodeList, ef)\n",
        "        faceDis = face_recognition.face_distance(knownEncodeList, ef)\n",
        "        matchIndex = np.argmin(faceDis) # Get index of the closest match\n",
        "        if matches[matchIndex]:\n",
        "            name = names[matchIndex].upper()\n",
        "            print(name)\n",
        "            y1, x2, y2, x1 = [i * 4 for i in fl] # Scale back up\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2) # Draw rectangle around face\n",
        "            cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 0, 0), cv2.FILLED) # Add a filled rectangle below face\n",
        "            cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_ITALIC, 1, (255, 255, 255), 2) # Add name text\n",
        "            if runit3:\n",
        "                os.system(f\"say '{name.lower()}'\") # Speak the name\n",
        "\n",
        "    # Detect hand landmarks if enabled\n",
        "    if runit:\n",
        "        hand_landmark_finder(img, h, w, c)\n",
        "\n",
        "    # Display the output\n",
        "    cv2.imshow('Camera', img)\n",
        "    cv2.waitKey(1) # Keep running until user exits\n",
        "\n",
        "# AMAZING information source: https://docs.opencv.org/4.x/index.html\n"
      ]
    }
  ]
}