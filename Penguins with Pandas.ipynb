{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas tutorial\n",
    "\n",
    "This notebook uses examples from the official [Pandas: Getting started tutorials](https://pandas.pydata.org/docs/getting_started/intro_tutorials/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the libraries that you plan to use\n",
    "\n",
    "It's good practice in a notebook to always load the libraries at the top of the notebook that you plan to use throughout the notebook. This preps the reader to understand what to expect in terms of commands and outputs. It also ensures that all the required functions and commands are available in the code cells, since you've loaded them into the computer's memory as the first set of instructions in the notebook.\n",
    "\n",
    "This notebook will use [`pandas`](https://pandas.pydata.org/) and [`matplotlib`](https://matplotlib.org/), which are two very popular libraries to analyze and visualize data respectively. It will also use [`numpy`](https://numpy.org/) for calculating some values, and [`seaboarn`](https://seaborn.pydata.org/) for some of the visualizations.\n",
    "\n",
    "Run the cell below to load all the libraries for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load your data\n",
    "\n",
    "You should store your data on the same server as your notebook whenever possible. Comma Separated Values (or `csv`) files are a very common format for storing Table-like information. The `read_csv` function in the `pandas` library, which the code above has shorted to `pd` when running `pandas` functions, can read in a `csv` file if you pass the function a string that contains the location of the file.\n",
    "\n",
    "For example, the `pd.read_csv` command in the cell below will look in the `data` folder found next to this notebook, and load the file named `penguins.csv` as a dataframe named `penguins`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv(\"data/penguins.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can take a look at the first few rows of the dataframe by calling its named, followed by `.head()`. Running the cell below will show you the first 5 rows of data, as well as the corresponding column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is about the Palmer Penguins\n",
    "\n",
    "![](https://github.com/allisonhorst/palmerpenguins/raw/main/man/figures/lter_penguins.png)\n",
    "\n",
    "Data were collected and made available by [Dr. Kristen Gorman](https://www.uaf.edu/cfos/people/faculty/detail/kristen-gorman.php) and the [Palmer Station, Antarctica LTER](https://pallter.marine.rutgers.edu/), a member of the [Long Term Ecological Research Network](https://lternet.edu/).\n",
    "\n",
    "\n",
    "The data set contains measurements on over 300 penguins, including their species, the island they were found on, the length and depth of their bills, the length of their flipper, their weight, their sex, and the year they were measured.\n",
    "\n",
    "![](https://github.com/allisonhorst/palmerpenguins/raw/main/man/figures/culmen_depth.png)\n",
    "\n",
    "For more information, you can visit [palmerpenguins by Allison Horst](https://allisonhorst.github.io/palmerpenguins/), who also made the images in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting columns\n",
    "\n",
    "Once you have your data loaded, you can start to create subsets of that data set for analysis. \n",
    "\n",
    "For example, the following command will create a new data frame `island` which only contains the column labeled `\"island\"` from the `penguins` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "island = penguins[[\"island\"]]\n",
    "island.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the following command will create a new dataframe named `mass_sex` which only keeps the columns related to the body mass and sex of the penguins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_sex = penguins[[\"body_mass_g\", \"sex\"]]\n",
    "mass_sex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting rows\n",
    "\n",
    "You can also filter your dataframe to only include certain observations that meet particular criteria. Here are some common things you might want to do with this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select rows if a column contains a specific categorical value\n",
    "\n",
    "For example, the following command will only keep rows that are about male penguins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_penguins = penguins[ penguins[\"sex\"] == \"male\" ]\n",
    "male_penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select rows if a column contains one of several categorical values\n",
    "\n",
    "You can select rows that have multiple categorical values. In this example, we are keeping only penguins that were measured in 2008 and 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_penguins = penguins[ penguins[\"year\"].isin([2008, 2009]) ]\n",
    "recent_penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above, just written differently\n",
    "recent_penguins = penguins[(penguins[\"year\"] == 2008) | (penguins[\"year\"] == 2009)]\n",
    "recent_penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only rows for which a value is known (discard NA)\n",
    "\n",
    "A lot of time datasets are missing values for certain observations. To discard rows for which a particular column is missing data, you can use the `.notna()` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_bill_length = penguins[penguins[\"bill_length_mm\"].notna()]\n",
    "has_bill_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I want to select rows and columns based off of their index (row and column number)\n",
    "\n",
    "When you create a dataframe, `pandas` will by default assign each row and column a number called an index. This is different than the `rowid` that came with this specific data set. You should already know how to pick a row based off of the `rowid` column using commands further up in this notebook. \n",
    "\n",
    "To use the indices provided by `pandas` to select rows 9 - 25 and columns 2-5, you can use the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.iloc[9:25, 2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** `pandas` will *include* the first index value, but *not include* the second index value in the selected rows and columns returned. For example, the row with index 25 and the column with index 5 are not included in this subset of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by a column or columns\n",
    "\n",
    "You can sort your dataframe by specifying the column or columns that you wish to sort by.\n",
    "\n",
    "For example, to sort by flipper length you can use the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.sort_values(by='flipper_length_mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the default behavior is to sort from smallest to largest, but you can change that by including an optional, `ascending=False` argument to the `sort_values()` method as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.sort_values(by='flipper_length_mm', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to sort by more than one column, you can run the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, only keep the rows where a value for sex is defined, then sort\n",
    "penguins[penguins['sex'].notna()].sort_values(by=['sex', 'flipper_length_mm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating values from the dataframe\n",
    "\n",
    "Now that you can wrangle the data in your dataframe a bit to create the perfect subset of data for analysis, you'll want to know how to crunch some important numbers. Suppose you wanted to compute the mean weight for male penguins and compare that to female penguins. \n",
    "\n",
    "First, create a dataframe with only male penguins in it, and then use the `np.mean()` function on just the column of data that contains the mass of the penguins. The commands would look like those below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the original data\n",
    "male_penguins = penguins[ penguins[\"sex\"] == \"male\" ]\n",
    "\n",
    "# compute the mean value for the specified column\n",
    "np.mean( male_penguins[\"body_mass_g\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the original data\n",
    "female_penguins = penguins[ penguins[\"sex\"] == \"female\" ]\n",
    "\n",
    "# compute the mean value for the specified column\n",
    "np.mean( female_penguins[\"body_mass_g\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you can do more than just compute a mean. Numpy has a whole slew of functions that you can call onto an array of values (or as we may call them, columns in a table). For a full reference of available `numpy` functions, see [Numpy Quickstart](https://numpy.org/doc/stable/user/quickstart.html).\n",
    "\n",
    "Some common functions to analyze numerical columns of data are:\n",
    "* `np.max()`. Returns the largest value in the column.\n",
    "* `np.min()`. Returns the smallest value in the column.\n",
    "* `np.median`. Returns the median value in the column.\n",
    "* `np.mean()`. Returns the mean value in the column.\n",
    "* `np.std()`. Returns the standard deviation of the values in the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Data\n",
    "\n",
    "Of course, you might be interested in visualizing some of the data in your data frame. We'll take a look at a few common visualizations to highlight the necessary `pandas` commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot\n",
    "\n",
    "You can call the `plot` command on a dataframe. You'll need to specify \"scatter\" as the `kind` argument, the columns you wish to use as the `x` and `y` arguments to construct the plot. Then, call `plt.show()` to render the graph in the notebook. In this example, the optional argument `alpha` is set to 0.5 to give each point a little transparency to help see overlapping points a bit clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.plot(kind='scatter', x='bill_length_mm', y=\"flipper_length_mm\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to color code by categorical variable, it is actually a little bit easier to use a different visualization library, called [`seaborn`](https://seaborn.pydata.org/) because its scatterplot function allows you to specify the categorical variable column with the `hue` argument. You can create a similar effect using `pandas` but the approach is a bit more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=penguins, x='bill_length_mm', y=\"flipper_length_mm\", hue='species', palette=\"viridis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box plots\n",
    "\n",
    "You can create a box plot by specifying the column that contains the numerical data using the `column` argument, and the column that contains the categorical variable you want to group by using the `by` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.plot(kind=\"box\", column=\"bill_length_mm\", by=\"species\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "\n",
    "You can specify the bins for your histogram by either creating an array that contains the edges of each bin. The `np.arange()` function lets you create an array with a specified starting and ending values, as well as the size of the increment to use to get from the the starting value to the ending value.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "np.arrange(6, 15, 3)\n",
    "```\n",
    "\n",
    "Would create an array that contains, 6, 9, and 12, since the command said to start at 6, end at 15, counting by 3. You don't include the ending value in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.plot(kind=\"hist\", column=\"flipper_length_mm\", bins=np.arange(170,240,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison sake, here's the same histogram made with `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=penguins, x=\"flipper_length_mm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=penguins, x=\"flipper_length_mm\", hue='species', bins=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
